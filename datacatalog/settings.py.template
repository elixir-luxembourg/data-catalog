#  DataCatalog
#  Copyright (C) 2020  University of Luxembourg
#
#  This program is free software: you can redistribute it and/or modify
#  it under the terms of the GNU Affero General Public License as
#  published by the Free Software Foundation, either version 3 of the
#  License, or (at your option) any later version.
#
#  This program is distributed in the hope that it will be useful,
#  but WITHOUT ANY WARRANTY; without even the implied warranty of
#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#  GNU Affero General Public License for more details.
#
#  You should have received a copy of the GNU Affero General Public License
#  along with this program.  If not, see <https://www.gnu.org/licenses/>.

import os

dirname = os.path.dirname(__file__)


class Config(object):
    BASE_URL = os.environ.get("BASE_URL", "") 
    SECRET_KEY = os.environ.get("APP_SECRET", b"")
    TITLE = 'Data Catalog'
    ENTITIES = {'dataset': 'datacatalog.models.dataset.Dataset',
                'project': 'datacatalog.models.project.Project',
                'study': 'datacatalog.models.study.Study'}
    DEFAULT_ENTITY = 'dataset'
    # CUSTOM FOLDER TO ALLOW OVERRIDING THE  DEFAULT TEMPLATES
    # TEMPLATES_EXTRA_FOLDER = ""
    # TO GIVE MORE WEIGHT TO CERTAIN FIELDS FOR THE SEARCH RESULTS
    SOLR_BOOST = {
        'dataset': 'dataset_title^5 dataset_text_^1',
        'project': 'project_title^5 project_description^2 project_text_^1',
        'study': 'study_title^5 study_description^2 study_text_^1',
    }

    # DEFAULT SORT FIELD
    SOLR_DEFAULT_SORT = {'dataset': 'title'}
    # THE FACETS THAT WILL SHOW UP ON THE LEFT SIDE MENU
    FACETS_ORDER = {
        'dataset': [
            ("data_types", "Data types"),
            ("disease", "Disease"),
            ("data_standards", "Data standards"),
        ],
        'project': [
            ("types", "Types"),
            ("keywords", "Keywords"),
        ],
        'study': [
            ("types", "Study types"),
            ("organisms", "Organisms"),
            ("disease", "Disease"),
            ("samples_type", "Samples types"),
        ]

    }

    # ENABLE/DISABLE EXTENDED SEARCH
    SOLR_QUERY_SEARCH_EXTENDED = True
    # ENABLE/DISABLE EXTENDED SEARCH 2 WAY INDEXING
    SOLR_QUERY_SEARCH_EXTENDED_2_WAY_INDEX = True
    # FIELDS WHICH ARE USED FOR EXTENDED SEARCH
    SOLR_QUERY_TEXT_FIELD_EXTENDED = {
        'dataset': [
            "title",
            "disease",
            "data_types",
            "data_standards",
        ],
        'project': [
            'description',
            'keywords',
            'title',
            'project_name',
            'types',
        ],
        'study': [
            'title',
            'organisms',
            'disease',
            'samples_type',
            'types',
        ]
    }

    # NUMBER OF SEARCH RESULTS DISPLAYED PER PAGE
    RESULTS_PER_PAGE = 8
    # SOLR URL
    SOLR_ENDPOINT = os.environ.get("SOLR_ENDPOINT", "http://localhost:8983/solr")
    # SOLR CORE
    SOLR_COLLECTION = 'datacatalog'
    # FOR ENTITIES IMPORT FROM JSON FILES
    JSON_FILE_PATH = {'dataset': 'data/imi_projects',
                      'project': 'data/imi_projects',
                      'study': 'data/imi_projects'}
    # EMAIL ADDRESS TO SEND ACCESS REQUEST TO
    EMAIL_RECIPIENT = ['data-catalog@elixir-luxembourg.org']
    # FLASK-MAIL CONFIGURATION
    MAIL_SERVER = os.environ.get("MAIL_SERVER", 'localhost')
    MAIL_PORT = int(os.environ.get("MAIL_PORT", "25"))
    MAIL_USE_TLS = False
    MAIL_USE_SSL = False
    # RECAPTCHA KEYS TO PROTECT THE REQUEST ACCESS FEATURE FROM BOTS
    RECAPTCHA_PUBLIC_KEY = os.environ.get("RECAPTCHA_PUBLIC", "")
    RECAPTCHA_PRIVATE_KEY = os.environ.get("RECAPTCHA_PRIVATE", "")
    # FAIR INDICATORS ARE DISPLAYED ONLY IF FAIR_VALUES_SHOW IS TRUE
    FAIR_VALUES_SHOW = os.environ.get("FAIR_VALUES_SHOW", "False").lower() in ('true', '1')
    # FAIR EVALUATION IS DISPLAYED ONLY IF FAIR_EVALUATIONS_SHOW IS TRUE
    FAIR_EVALUATIONS_SHOW = os.environ.get("FAIR_EVALUATIONS_SHOW", "True").lower() in ('true', '1')
    FAIR_VALUES = {1: {'class': 'good', 'text': 'good'},
                   2: {'class': 'medium', 'text': 'moderate'},
                   3: {'class': 'bad', 'text': 'bad'}}

    # WHICH FIELDS ARE USED FOR DEFAULT SEARCH
    SOLR_QUERY_TEXT_FIELD = {
        'dataset': [
            "id",
            "title",
            "disease",
            "data_types",
            "data_standards",
        ],
        'project': [
            'id',
            'description',
            'keywords',
            'title',
            'project_name',
            'types',
        ],
        'study': [
            'id',
            'title',
            'organisms',
            'disease',
            'samples_type',
            'types',
        ]

    }
    # the entities that appears in the menu / navbar
    ENTITIES_MENU = ['project', 'dataset', 'study']

    # GEO IMPORTER
    # THIS FOLDER SHOULD CONTAIN '.TXT' FILES WITH 'DISEASE' AS NAME OF FILE CONTAINING GEO SERIES. FOR EX: ASTHMA.TXT
    # GEO_FILE_PATH = 'tests/data/geo_studies/'
    GEO_FILE_PATH = {'dataset': 'data/geo_studies',
                     'project': 'data/geo_studies',
                     'study': 'data/geo_studies'}
    GEO_TEMP_FOLDER = 'tests/data/geo_studies/temp_files/'
    # AUTHENTICATION_METHOD CAN BE LDAP OR PYOIDC
    AUTHENTICATION_METHOD = os.environ.get("AUTHENTICATION_METHOD", "LDAP")
    # LDAP configuration
    LDAP_HOST = os.environ.get("LDAP_HOST", "ldaps://xxxxxxxxxx")
    LDAP_USERNAME = os.environ.get("LDAP_USERNAME", "xxxx")
    LDAP_PASSWORD = os.environ.get("LDAP_PASSWORD", "xxxx")
    LDAP_BASE_DN = os.environ.get("LDAP_BASE_DN", "xxxx")
    LDAP_USER_GROUPS_FIELD = os.environ.get("LDAP_USER_GROUPS_FIELD", "xxxx")
    AUTHENTICATION_DICT = {LDAP_USERNAME: LDAP_PASSWORD}
    # OIDC CONFIGURATION
    PYOIDC_CLIENT_ID = os.environ.get("PYOIDC_CLIENT_ID", "")
    PYOIDC_CLIENT_SECRET = os.environ.get("PYOIDC_CLIENT_SECRET", "")
    PYOIDC_IDP_URL = os.environ.get("PYOIDC_IDP_URL", "")
    # DISPLAY THE 'LOGIN' LINK IN NAVBAR
    SHOW_LOGIN = False
    # ACCESS HANDLER (used for access requests)
    # Rems, RemsOidc or Email
    # RemsOidc handler will use rems to create access requests and pull requests statuses but actual accesses will be
    # pulled from user roles coming from OIDC provider
    ACCESS_HANDLERS = {
        "dataset": os.environ.get("ACCESS_HANDLERS", "Email")
    }
    # If REMS handler
    REMS_API_KEY = os.environ.get("REMS_API_KEY", "")
    REMS_URL = os.environ.get("REMS_URL", "")
    REMS_API_USER = os.environ.get("REMS_API_USER", "")
    REMS_WORKFLOW_ID = int(os.environ.get("REMS_WORKFLOW_ID", "1"))
    REMS_ORGANIZATION_ID = os.environ.get("REMS_ORGANIZATION_ID", "")
    REMS_LICENSES = [1]
    REMS_VERIFY_SSL = os.environ.get("REMS_VERIFY_SSL", "False").lower() in ('true', '1')
    # Export entity as dats
    ALLOW_ENTITY_EXPORT = os.environ.get("ALLOW_ENTITY_EXPORT", "False").lower() in ('true', '1')
    # Parameters for DAISY connector
    DAISY_VERIFY_SSL = os.environ.get("DAISY_VERIFY_SSL", "False").lower() in ('true', '1')
    DAISY_API_URLS = {
        'dataset':  os.environ.get("DAISY_API_URLS_DATASET", ""),
        'project':  os.environ.get("DAISY_API_URLS_PROJECT", ""),
    }
    # Logger configuration
    LOGGING_CONFIG = {
        'version': 1,
        'disable_existing_loggers': True,
        'formatters': {
            'standard': {
                'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s'
            },
        },
        'handlers': {
            'default': {
                'level': 'DEBUG',
                'formatter': 'standard',
                'class': 'logging.StreamHandler',
                'stream': 'ext://sys.stdout',
            },
            'file': {
                'level': 'DEBUG',
                'formatter': 'standard',
                'class': 'logging.FileHandler',
                'filename': 'datacatalog.log'
            }
        },
        'loggers': {
            'root': {
                'handlers': ['default', 'file'],
                'level': 'WARNING',
                'propagate': True
            },
            'datacatalog': {
                'level': 'DEBUG',
            },
            'werkzeug': {
                'level': 'INFO'
            }
        }
    }

    # For entities attached files
    PUBLIC_FILE_STORAGE_ROOT = os.environ.get("PUBLIC_FILE_STORAGE_ROOT", "") 


    # Autocomplete
    TOTAL_SUGGESTED_TERMS = 2
    TOTAL_SUGGESTED_ENTITY_TITLES = 4

    # Dats
    DATS_SCHEMAS_FOLDER = os.environ.get("DATS_SCHEMAS_FOLDER", "") 
    DATS_CONTEXTS_FOLDER = os.environ.get("DATS_CONTEXTS_FOLDER", "")  
    # URL SCHEME, use to force a specific URL scheme when building full URLs (e.g. sitemap URL)
    # SCHEME = 'https'

    # NO STORAGES
    CONTACT_ACCESS_RECIPIENT = ""  # who to contact if no storages are defined
    CONTACT_ACCESS_BODY = ""  # the body of the email to send if no storages are defined

    HOSTED_STRING = "hosted"


class DockerConfig(Config):
    SOLR_ENDPOINT = "http://solr:8983/solr"
    CACHE_CONFIG = {'CACHE_TYPE': 'null', 'CACHE_DIR': "cache",
                    'CACHE_THRESHOLD': 10000, 'CACHE_TIMEOUT': 0}


class ProdConfig(Config):
    # Cache configuration, see Flask-Cache documentation for syntax,
    # for filesystem cache, set CACHE_DIR with a writable folder path.
    CACHE_CONFIG = {'CACHE_TYPE': 'filesystem', 'CACHE_DIR': "cache",
                    'CACHE_THRESHOLD': 10000, 'CACHE_TIMEOUT': 0}
    SECRET_KEY = b""


class DevConfig(Config):
    DEBUG = True
    # cache is disabled for dev environment
    CACHE_CONFIG = {'CACHE_TYPE': 'null', 'CACHE_DIR': "cache",
                    'CACHE_THRESHOLD': 10000, 'CACHE_TIMEOUT': 0}
    SECRET_KEY = b""


class TestConfig(Config):
    DEBUG = True
    ASSETS_DEBUG = True
    TESTING = True
    CACHE_CONFIG = {'CACHE_TYPE': 'null'}
    WTF_CSRF_ENABLED = False
    SOLR_ENDPOINT = 'http://localhost:8983/solr'
    SOLR_COLLECTION = 'datacatalog_test'
    TEST_GEO_STUDY_LIST_PATH = "tests/geo_studies_test/test.txt"

    JSON_FILE_PATH = {'dataset': 'tests/data/imi_projects_test',
                      'project': 'tests/data/imi_projects_test',
                      'study': 'tests/data/imi_projects_test'}
